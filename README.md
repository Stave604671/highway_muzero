# highway_muzero


# 目前遇到的问题

1、当前使用的观测空间和连续型动作空间的特点，就是训练过程中车辆会很容易失控出轨，导致前期震荡很严重，
模型训练过程中基本学不到什么知识，或者学习很慢，导致收敛速度和效果很差。

2、因为上面这个原因，导致total reward曲线震荡。

3、似乎离散型动作空间的逻辑可以缓解这个过程，而且离散型动作空间下reward更合理，mean reward的上升也正常些。
而且离散型动作空间的逻辑更加高级，连续型动作空间的代码更久一些，可以把两边代码一起升级一下。

# 核心实验步骤【为避免浪费训练时长】

1、涉及到对比实验，或者对比效果的情况，需要给每个配置文件单独写一个py文件，并且在文件名体现核心

2、每生成一个对比图，将对应的截图保存提交到代码中，在readme记录结论，避免重复实验


# 已知的训练结论

